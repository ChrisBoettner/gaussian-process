{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Float64 for more stable matrix inversions.\n",
    "from jax import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "from jax import jit, tree_map\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jaxtyping import install_import_hook, Array\n",
    "from copy import deepcopy\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from gpjax.base import meta_leaves\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from jax.stages import Wrapped\n",
    "import warnings\n",
    "import optax as ox\n",
    "from tqdm import tqdm\n",
    "\n",
    "with install_import_hook(\"gpjax\", \"beartype.beartype\"):\n",
    "    import gpjax as gpx\n",
    "    from gpjax.kernels import Constant, Linear, RBF, Periodic, PoweredExponential\n",
    "\n",
    "key = jr.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from beartype.typing import Union\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Float\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "\n",
    "from gpjax.base import param_field\n",
    "from gpjax.kernels.base import AbstractKernel\n",
    "from gpjax.kernels.stationary.utils import squared_distance\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    ScalarFloat,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OrnsteinUhlenbeck(AbstractKernel):\n",
    "    r\"\"\"The Ornstein-Uhlenbeck kernel.\"\"\"\n",
    "\n",
    "    lengthscale: Union[ScalarFloat, Float[Array, \" D\"]] = param_field(\n",
    "        jnp.array(1.0), bijector=tfb.Softplus()\n",
    "    )\n",
    "    variance: ScalarFloat = param_field(jnp.array(1.0), bijector=tfb.Softplus())\n",
    "    name: str = \"OU\"\n",
    "\n",
    "    def __call__(self, x: Float[Array, \" D\"], y: Float[Array, \" D\"]) -> ScalarFloat:\n",
    "        r\"\"\"Compute the OU kernel between a pair of arrays.\n",
    "\n",
    "        Evaluate the kernel on a pair of inputs $`(x, y)`$ with lengthscale parameter\n",
    "        $`\\ell`$ and variance $`\\sigma^2`$:\n",
    "        ```math\n",
    "        k(x,y)=\\sigma^2\\exp\\Bigg(- \\frac{\\lVert x - y \\rVert_2}{2 \\ell^2} \\Bigg)\n",
    "        ```\n",
    "\n",
    "        Args:\n",
    "            x (Float[Array, \" D\"]): The left hand argument of the kernel function's call.\n",
    "            y (Float[Array, \" D\"]): The right hand argument of the kernel function's call.\n",
    "\n",
    "        Returns:\n",
    "            ScalarFloat: The value of $`k(x, y)`$.\n",
    "        \"\"\"\n",
    "        x = self.slice_input(x) / self.lengthscale\n",
    "        y = self.slice_input(y) / self.lengthscale\n",
    "        K = self.variance * jnp.exp(-0.5 * jnp.sum(jnp.abs(x - y)))\n",
    "        return K.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        posterior: gpx.gps.AbstractPosterior,\n",
    "        max_log_likelihood: Optional[float] = None,\n",
    "        n_data: Optional[int] = None,\n",
    "        parent=Optional[\"Node\"],\n",
    "    ):\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "\n",
    "        self.update(\n",
    "            posterior,\n",
    "            max_log_likelihood,\n",
    "            n_data,\n",
    "        )\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        posterior: gpx.gps.AbstractPosterior,\n",
    "        max_log_likelihood: Optional[float] = None,\n",
    "        n_data: Optional[int] = None,\n",
    "    ):\n",
    "        self.posterior = posterior\n",
    "\n",
    "        self.n_parameter = sum(\n",
    "            leaf[0][\"trainable\"]\n",
    "            for leaf in meta_leaves(posterior)\n",
    "            if isinstance(leaf[0], dict)\n",
    "        )  # number of trainable parameter\n",
    "\n",
    "        if n_data is not None:\n",
    "            self.n_data = np.log(n_data)\n",
    "\n",
    "        if max_log_likelihood is not None:\n",
    "            self.max_log_likelihood = max_log_likelihood\n",
    "            if self.n_data is not None:\n",
    "                self.bic = self.n_parameter * self.n_data - 2 * self.max_log_likelihood\n",
    "\n",
    "    def add_child(\n",
    "        self,\n",
    "        node: \"Node\",\n",
    "    ):\n",
    "        self.children.append(node)\n",
    "\n",
    "\n",
    "class KernelSearch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_library: list[gpx.kernels.AbstractKernel],\n",
    "        data: gpx.Dataset,\n",
    "        obs_stddev: float | Array = 1,\n",
    "        fit_obs_stddev: bool = False,\n",
    "        likelihood: Optional[gpx.likelihoods.AbstractLikelihood] = None,\n",
    "        objective: Optional[gpx.objectives.AbstractObjective | Wrapped] = None,\n",
    "        mean_function: Optional[gpx.mean_functions.AbstractMeanFunction] = None,\n",
    "        root_kernel: Optional[gpx.kernels.AbstractKernel] = None,\n",
    "        num_iters: int = 1000,\n",
    "        parallelise: bool = True,\n",
    "        n_cores: int = 8,\n",
    "        verbosity: int = 1,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kernel_library : list[gpx.kernels.AbstractKernel]\n",
    "            _description_\n",
    "        data : gpx.Dataset\n",
    "            _description_\n",
    "        obs_stddev : float | Array, optional\n",
    "            _description_, is ignored if custom likelihood is given, by default 1\n",
    "        fit_obs_stddev : bool, optional\n",
    "            _description_, is ignored if custom likelihood is given, by default False\n",
    "        likelihood : Optional[gpx.likelihoods.AbstractLikelihood], optional\n",
    "            _description_, by default None, which defaults to the Gaussian likelihood with standard deviation given by obs_stddev.\n",
    "        objective : Optional[gpx.objectives.AbstractObjective  |  Wrapped], optional\n",
    "            _description_, by default None, which defaults to a jit-compiled negative marginal log-likelihood (for a gaussian likelihood), must be adapted if the likelihood is not Gaussian\n",
    "        mean_function : Optional[gpx.mean_functions.AbstractMeanFunction], optional\n",
    "            _description_, by default None, which sets the mean to zero\n",
    "        root_kernel : gpx.kernels.AbstractKernel\n",
    "        _description_\n",
    "        num_iters : int, optional\n",
    "            _description_, by default 1000\n",
    "        parallelise : bool, optional\n",
    "            _description_, by default True\n",
    "        n_cores : int, optional\n",
    "            _description_, by default 8\n",
    "        verbosity : int, optional\n",
    "            _description_, by default 1\n",
    "        \"\"\"\n",
    "        if isinstance(obs_stddev, float):\n",
    "            obs_stddev = jnp.array(obs_stddev)\n",
    "        if likelihood is None:\n",
    "            likelihood = gpx.likelihoods.Gaussian(\n",
    "                num_datapoints=data.n, obs_stddev=obs_stddev\n",
    "            )\n",
    "            likelihood = likelihood.replace_trainable(obs_stddev=fit_obs_stddev)  # type: ignore\n",
    "        if objective is None:\n",
    "            objective = jit(gpx.objectives.ConjugateMLL(negative=True))\n",
    "        if mean_function is None:\n",
    "            mean_function = gpx.mean_functions.Zero()\n",
    "\n",
    "        self.likelihood = likelihood\n",
    "        self.objective = objective\n",
    "        self.data = data\n",
    "\n",
    "        self.kernel_library = kernel_library\n",
    "        self.parallelise = parallelise\n",
    "        self.n_cores = n_cores\n",
    "        self.num_iters = num_iters\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "        self.best_model = None\n",
    "\n",
    "        if root_kernel is not None:\n",
    "            self.root = [\n",
    "                Node(\n",
    "                    likelihood\n",
    "                    * gpx.gps.Prior(\n",
    "                        mean_function=mean_function,\n",
    "                        kernel=self._const_kernel() * root_kernel,\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            self.root = [\n",
    "                Node(\n",
    "                    likelihood\n",
    "                    * gpx.gps.Prior(\n",
    "                        mean_function=mean_function,\n",
    "                        kernel=self._const_kernel() * kernel,  # type: ignore\n",
    "                    )\n",
    "                )\n",
    "                for kernel in kernel_library\n",
    "            ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _const_kernel(trainable=False):\n",
    "        return Constant(constant=jnp.array(1.0)).replace_trainable(constant=trainable)  # type: ignore\n",
    "\n",
    "    def fit(self, posterior) -> tuple[gpx.gps.AbstractPosterior, float]:\n",
    "        static_tree = tree_map(lambda x: not (x), posterior.trainables)\n",
    "        optim = ox.chain(\n",
    "            ox.adamw(learning_rate=3e-4),\n",
    "            ox.masked(\n",
    "                ox.set_to_zero(),\n",
    "                static_tree,\n",
    "            ),\n",
    "        )\n",
    "        try:\n",
    "            optimized_posterior, history = gpx.fit(\n",
    "                model=posterior,\n",
    "                objective=self.objective,\n",
    "                train_data=self.data,\n",
    "                optim=optim,\n",
    "                key=key,\n",
    "                num_iters=self.num_iters,\n",
    "                verbose=True if self.verbosity >= 2 else False,\n",
    "            )\n",
    "            max_log_likelihood = -float(history[-1])\n",
    "        except FloatingPointError:\n",
    "            return posterior, -np.inf\n",
    "        return optimized_posterior, max_log_likelihood\n",
    "\n",
    "    def expand_node(self, node):\n",
    "        for kernel_operation in [gpx.kernels.ProductKernel, gpx.kernels.SumKernel]:\n",
    "            for ker in self.kernel_library:\n",
    "                kernel = deepcopy(node.posterior.prior.kernel)\n",
    "\n",
    "                new_kernel = deepcopy(ker)  # type: ignore\n",
    "                if kernel_operation == gpx.kernels.SumKernel:\n",
    "                    # create new additive term with tracer constant\n",
    "                    # the first kernel in the new term has a trainable constant\n",
    "                    new_kernel = gpx.kernels.ProductKernel(kernels=[self._const_kernel(), new_kernel])  # type: ignore\n",
    "                if kernel_operation == gpx.kernels.ProductKernel:\n",
    "                    # further kernels have variance fixed, so that we only have one constant\n",
    "                    try:\n",
    "                        new_kernel = new_kernel.replace_trainable(variance=False)  # type: ignore\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                composite_kernel = kernel_operation(kernels=[kernel, new_kernel])  # type: ignore\n",
    "\n",
    "                new_prior = gpx.gps.Prior(\n",
    "                    mean_function=node.posterior.prior.mean_function,\n",
    "                    kernel=composite_kernel,\n",
    "                )\n",
    "                new_posterior = self.likelihood * new_prior\n",
    "                node.add_child(Node(*self.fit(new_posterior), self.data.n, parent=node))\n",
    "\n",
    "    def compute_layer(self, layer, current_depth):\n",
    "        if self.verbosity == 1:\n",
    "            for node in tqdm(layer, desc=f\"Fitting Layer {current_depth +1}\"):\n",
    "                node.update(*self.fit(node.posterior), self.data.n)\n",
    "        else:\n",
    "            [node.update(*self.fit(node.posterior), self.data.n) for node in layer]\n",
    "\n",
    "    def select_top_nodes(self, layer, bic_threshold, n_leafs):\n",
    "        sorted_tuple = sorted((node.bic, node) for node in layer)\n",
    "        # return first n_leafs nodes\n",
    "        top_nodes = [node for _, node in sorted_tuple][:n_leafs]\n",
    "        # filter for bic threshold\n",
    "        top_nodes = [node for node in top_nodes if node.bic < bic_threshold]\n",
    "        if top_nodes:\n",
    "            self.best_model = top_nodes[0]\n",
    "        return top_nodes\n",
    "\n",
    "    def expand_layer(self, layer):\n",
    "        if self.verbosity >= 1:\n",
    "            print(\"Expanding Top Nodes...\")\n",
    "        next_layer = []\n",
    "        for node in layer:\n",
    "            self.expand_node(node)\n",
    "            next_layer.extend(node.children)\n",
    "        return next_layer\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        depth: int = 10,\n",
    "        n_leafs: int = 3,\n",
    "    ):\n",
    "        layer = self.root\n",
    "\n",
    "        current_depth = 0\n",
    "        bic_threshold = np.inf\n",
    "        for current_depth in range(depth):\n",
    "            self.compute_layer(layer, current_depth)\n",
    "            if current_depth == 0:\n",
    "                self.best_model = sorted((node.bic, node) for node in layer)[0][1]\n",
    "\n",
    "            current_bics = sorted([node.bic for node in layer])\n",
    "            if current_bics[0] > bic_threshold:\n",
    "                if self.verbosity >= 1:\n",
    "                    print(\"No more improvements found! Terminating early..\\n\")\n",
    "                    break\n",
    "\n",
    "            if self.verbosity >= 1:\n",
    "                print(f\"Layer {current_depth+1} || Current BICs: {current_bics}\")\n",
    "\n",
    "            layer = self.select_top_nodes(layer, bic_threshold, n_leafs)\n",
    "            bic_threshold = current_bics[0]  # min bic of current layer\n",
    "            layer = self.expand_layer(layer)\n",
    "\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"Loop didn't run. Is depth > 0?\")\n",
    "        if self.verbosity >= 1:\n",
    "            print(f\"Terminated on layer: {current_depth+1}.\")\n",
    "            print(f\"Final log likelihood: {self.best_model.max_log_likelihood}\")\n",
    "            print(f\"Final number of model paramter: {self.best_model.n_parameter}\")\n",
    "        return self.best_model.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "n = 100\n",
    "noise = 0.3\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "x = jr.uniform(key=key, minval=-3.0, maxval=3.0, shape=(n,)).reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(subkey, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "\n",
    "xtest = jnp.linspace(-3.5, 3.5, 500).reshape(-1, 1)\n",
    "ytest = f(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_library = [\n",
    "    Linear(),\n",
    "    RBF(),\n",
    "    Periodic(),\n",
    "    PoweredExponential(power=jnp.array(0.8)),\n",
    "]  # default powered exponential has infinite parameter for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos :\n",
    "# implement Ornstein-Uhlenbeck kernel\n",
    "# parallelize\n",
    "# test\n",
    "\n",
    "# rescale input! (i.e. if mean func is zero, should be centered at zero, maybe rather do that in data fit rountine though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352eb1ff0a694e278bdd34241ab34d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcc2eb731f34e4e9f105627124a6cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea8b35024ac48c6b2c7a64d97fedaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c335ef8b155c4e1681abe992e2c47f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 || Current BICs: [142.94699057223028, 289.34897589599353, 1098.1062431512441, 1178.9328839432758]\n",
      "Expanding Top Nodes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6518036e9a04e3d9a11f0efc03a8a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45368ae96374f28bf92645b7c669f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree = KernelSearch(\n",
    "    kernel_library,\n",
    "    data=D,\n",
    "    obs_stddev=0.3,\n",
    "    verbosity=2,\n",
    "    num_iters=500,\n",
    ")\n",
    "\n",
    "model = tree.search(depth=5, n_leafs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = model.predict(train_data=D, test_inputs=signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hobby",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
